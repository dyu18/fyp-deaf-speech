{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import os\n",
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Whisper model\n",
    "model_name = \"medium.en\"\n",
    "model = whisper.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_text = \"The Rainbow Passage When the sunlight strikes raindrops in the air, they act as a prism and form a rainbow. The rainbow is a division of white light into many beautiful colors. These take the shape of a long round arch, with its path high above, and its two ends apparently beyond the horizon. There is , according to legend, a boiling pot of gold at one end. People look, but no one ever finds it. When a man looks for something beyond his reach, his friends say he is looking for the pot of gold at the end of the rainbow. Throughout the centuries people have explained the rainbow in various ways. Some have accepted it as a miracle without physical explanation. To the Hebrews it was a token that there would be no more universal floods. The Greeks used to imagine that it was a sign from the gods to foretell war or heavy rain. The Norsemen considered the rainbow as a bridge over which the gods passed from earth to their home in the sky. Others have tried to explain the phenomenon physically. Aristotle thought that the rainbow was caused by reflection of the sun's rays by the rain. Since then physicists have found that it is not reflection, but refraction by the raindrops which causes the rainbows. Many complicated ideas about the rainbow have been formed. The difference in the rainbow depends considerably upon the size of the drops, and the width of the colored band increases as the size of the drops increases. The actual primary rainbow observed is said to be the effect of super-imposition of a number of bows. If the red of the second bow falls upon the green of the first, the result is to give a bow with an abnormally wide yellow band, since red and green light when mixed form yellow. This is a very common type of bow, one showing mainly red and yellow, with little or no green or blue.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NH group: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing NH1RPDR2.WAV...\n",
      "Transcribing NH2RPDR1.wav...\n",
      "Transcribing NH3RPDR2.WAV...\n",
      "Transcribing NH4RPDR2.wav...\n",
      "Transcribing NH5RPDR2.wav...\n",
      "Transcribing NH6RPDR2.wav...\n",
      "Transcribing NH7RPDR1.wav...\n",
      "Transcribing NH8RPDR2.wav...\n",
      "Transcribing NH9RPDR2.wav...\n",
      "Transcribing NH10RPDR2.wav...\n"
     ]
    }
   ],
   "source": [
    "transcriptions = {}\n",
    "all_references = []\n",
    "all_hypotheses = []\n",
    "\n",
    "audio_dir = os.path.join(\"CorpusOfDeafSpeech\",\"Normal Hearing\")\n",
    "NH_subject_list = [\"NH01\",\"NH02\",\"NH03\",\"NH04\",\"NH05\",\"NH06\",\"NH07\",\"NH08\",\"NH09\",\"NH10\"]\n",
    "passage_name = \"RP\"\n",
    "# Iterate over audio files\n",
    "for (i,NH_subject) in enumerate(NH_subject_list): \n",
    "    i = i + 1\n",
    "    dir_path = os.path.join(audio_dir, NH_subject, \"Passages\")\n",
    "\n",
    "    for filename in os.listdir(dir_path):\n",
    "        if (filename.endswith(\".wav\") or filename.endswith(\".WAV\")) and filename.startswith(\"NH\"+str(i)+passage_name):\n",
    "            file_path = os.path.join(dir_path, filename)\n",
    "            print(f\"Transcribing {filename}...\")\n",
    "            \n",
    "            # Transcribe the audio file\n",
    "            result = model.transcribe(file_path, language=\"en\")\n",
    "            transcription = result[\"text\"]\n",
    "            transcriptions[filename] = transcription\n",
    "            \n",
    "            # Save transcription to file\n",
    "            filename_stripped = os.path.splitext(filename)[0]  # Get filename without extension\n",
    "            txt_path = os.path.join(dir_path,filename_stripped+\"_medium.en.txt\")\n",
    "            with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(transcription)\n",
    "            # print(f\"Transcription saved to {txt_path}\")\n",
    "            \n",
    "            # Append reference and hypothesis for WER calculation\n",
    "            all_references.append(reference_text)\n",
    "            all_hypotheses.append(transcription)\n",
    "    \n",
    "    \n",
    "\n",
    "# Concatenate all references and hypotheses\n",
    "concatenated_reference = \" \".join(all_references)\n",
    "concatenated_hypothesis = \" \".join(all_hypotheses)\n",
    "\n",
    "# Calculate overall WER\n",
    "overall_wer_NH = wer(concatenated_reference, concatenated_hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load transcribed text and calculate WER: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER_NH: 0.05225225225225225\n"
     ]
    }
   ],
   "source": [
    "all_references = []\n",
    "all_hypotheses = []\n",
    "\n",
    "audio_dir = os.path.join(\"CorpusOfDeafSpeech\",\"Normal Hearing\")\n",
    "NH_subject_list = [\"NH01\",\"NH02\",\"NH03\",\"NH04\",\"NH05\",\"NH06\",\"NH07\",\"NH08\",\"NH09\",\"NH10\"]\n",
    "passage_name = \"RP\"\n",
    "# Iterate over audio files\n",
    "for (i,NH_subject) in enumerate(NH_subject_list): \n",
    "    i = i + 1\n",
    "    dir_path = os.path.join(audio_dir, NH_subject, \"Passages\")\n",
    "\n",
    "    for filename in os.listdir(dir_path):\n",
    "        if (filename.endswith(\".wav\") or filename.endswith(\".WAV\")) and filename.startswith(\"NH\"+str(i)+passage_name):\n",
    "            \n",
    "            filename_stripped = os.path.splitext(filename)[0]  # Get filename without extension\n",
    "            txt_path = os.path.join(dir_path,filename_stripped+\"_medium.en.txt\")\n",
    "            with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                transcription = f.read()\n",
    "            \n",
    "            # Append reference and hypothesis for WER calculation\n",
    "            all_references.append(reference_text)\n",
    "            all_hypotheses.append(transcription)\n",
    "    \n",
    "\n",
    "# Concatenate all references and hypotheses\n",
    "concatenated_reference = \" \".join(all_references)\n",
    "concatenated_hypothesis = \" \".join(all_hypotheses)\n",
    "\n",
    "# Calculate overall WER\n",
    "overall_wer_NH = wer(concatenated_reference, concatenated_hypothesis)\n",
    "print(f\"WER_NH: {overall_wer_NH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model size comparison\n",
    "\n",
    "| model size |  WER   |\n",
    "| ---------- | ------ |\n",
    "| tiny       | 11.77% |\n",
    "| tiny.en    |  9.61% |\n",
    "| base       |  8.92% |\n",
    "| base.en    |  7.09% |\n",
    "| small      |  6.91% |\n",
    "| small.en   |  5.83% |\n",
    "| medium     |  5.68% |\n",
    "| medium.en  |  5.23% |\n",
    "| large (v3) | 21.86% |\n",
    "| turbo (v3) | 19.49% |\n",
    "\n",
    "another visualisaton: \n",
    "\n",
    "| model size |  WER (English-only model)  |  WER (multilingual model)  |\n",
    "| ---------- | -------------------------- | -------------------------- |\n",
    "| tiny       |  9.61% | 11.77% |\n",
    "| base       |  7.09% |  8.92% |\n",
    "| small      |  5.83% |  6.91% |\n",
    "| medium     |  5.23% |  5.68% |\n",
    "| large (v3) |   N/A  | 21.86% |\n",
    "| turbo (v3) |   N/A  | 19.49% |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43843843843843844\n",
      "0.036036036036036036\n",
      "0.11411411411411411\n",
      "0.08408408408408409\n",
      "0.07207207207207207\n",
      "0.12612612612612611\n",
      "0.5165165165165165\n",
      "0.03303303303303303\n",
      "0.3183183183183183\n",
      "0.21021021021021022\n"
     ]
    }
   ],
   "source": [
    "# show WER of each file trascribed by \"turbo\" model\n",
    "for ref,hyp in zip(all_references, all_hypotheses):\n",
    "    print(wer(ref,hyp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HI group: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing S1RPDR2.wav...\n",
      "Transcribing S2RPDR2.WAV...\n",
      "Transcribing S3RPDR2.wav...\n",
      "Transcribing S4RPDR2.wav...\n",
      "Transcribing S5RPDR2.WAV...\n",
      "Transcribing S6RPDR2.WAV...\n",
      "Transcribing S7RPDR2.wav...\n",
      "Transcribing S8RPDR2.WAV...\n",
      "Transcribing S9RPDR2.wav...\n",
      "Transcribing S10RPDR2.WAV...\n",
      "Transcribing S12RPDR2.wav...\n",
      "Transcribing S13RPDR2.WAV...\n",
      "Transcribing S14RPDR2.wav...\n",
      "Transcribing S15RPDR2.wav...\n",
      "Transcribing S16RPDR2.wav...\n",
      "Transcribing S17RPDR2.wav...\n",
      "Transcribing S18RPDR2.WAV...\n",
      "Transcribing S19RPDR2.wav...\n",
      "Transcribing S20RPDR2.WAV...\n",
      "Transcribing S21RPDR2.wav...\n",
      "Transcribing S22RPDR2.wav...\n",
      "Transcribing S23RPDR2.wav...\n",
      "Transcribing S24RPDR2.WAV...\n",
      "Transcribing S25RPDR2.WAV...\n",
      "Transcribing S26RPDR2.wav...\n",
      "Transcribing S27RPDR2.wav...\n",
      "Transcribing S28RPDR2.wav...\n",
      "Transcribing S29RPDR2.wav...\n",
      "Transcribing S30RPDR2.wav...\n",
      "Transcribing S31RPDR2.wav...\n"
     ]
    }
   ],
   "source": [
    "transcriptions = {}\n",
    "all_references = []\n",
    "all_hypotheses = []\n",
    "\n",
    "audio_dir = os.path.join(\"CorpusOfDeafSpeech\",\"Deaf\") #\"CorpusOfDeafSpeech\" \n",
    "passage_name = \"RP\"\n",
    "# Iterate over audio files\n",
    "for i in range(31):\n",
    "    i = i + 1\n",
    "    HI_subject = \"Subject \"+str(i)\n",
    "    dir_path = os.path.join(audio_dir, HI_subject, \"Passages\")\n",
    "    if i != 11:     # subject 11 doesn't have any passage recordings\n",
    "        for filename in os.listdir(dir_path):\n",
    "            if (filename.endswith(\".wav\") or filename.endswith(\".WAV\")) and filename.startswith(\"S\"+str(i)+passage_name):\n",
    "                file_path = os.path.join(dir_path, filename)\n",
    "                print(f\"Transcribing {filename}...\")\n",
    "                \n",
    "                # Transcribe the audio file\n",
    "                result = model.transcribe(file_path)\n",
    "                transcription = result[\"text\"]\n",
    "                transcriptions[filename] = transcription\n",
    "                \n",
    "                # Save transcription to file\n",
    "                filename_stripped = os.path.splitext(filename)[0]  # Get filename without extension\n",
    "                txt_path = os.path.join(dir_path,filename_stripped+\"_medium.en.txt\")\n",
    "                with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(transcription)\n",
    "                # print(f\"Transcription saved to {txt_path}\")\n",
    "                \n",
    "                # Append reference and hypothesis for WER calculation\n",
    "                all_references.append(reference_text)\n",
    "                all_hypotheses.append(transcription)\n",
    "    \n",
    "    \n",
    "\n",
    "# Concatenate all references and hypotheses\n",
    "concatenated_reference = \" \".join(all_references)\n",
    "concatenated_hypothesis = \" \".join(all_hypotheses)\n",
    "\n",
    "# Calculate overall WER\n",
    "overall_wer_HI = wer(concatenated_reference, concatenated_hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6927927927927928\n"
     ]
    }
   ],
   "source": [
    "print(overall_wer_HI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting transcription for S1RPDR2.wav...\n",
      "Getting transcription for S4RPDR2.wav...\n",
      "Getting transcription for S5RPDR2.WAV...\n",
      "Getting transcription for S8RPDR2.WAV...\n",
      "Getting transcription for S9RPDR2.wav...\n",
      "Getting transcription for S10RPDR2.WAV...\n",
      "Getting transcription for S6RPDR2.WAV...\n",
      "Getting transcription for S7RPDR2.wav...\n",
      "Getting transcription for S12RPDR2.wav...\n",
      "Getting transcription for S15RPDR2.wav...\n",
      "Getting transcription for S23RPDR2.wav...\n",
      "Getting transcription for S25RPDR2.WAV...\n",
      "Getting transcription for S26RPDR2.wav...\n",
      "Getting transcription for S27RPDR2.wav...\n",
      "Getting transcription for S29RPDR2.wav...\n",
      "Getting transcription for S30RPDR2.wav...\n",
      "Getting transcription for S31RPDR2.wav...\n",
      "Getting transcription for S2RPDR2.WAV...\n",
      "Getting transcription for S3RPDR2.wav...\n",
      "Getting transcription for S13RPDR2.WAV...\n",
      "Getting transcription for S14RPDR2.wav...\n",
      "Getting transcription for S16RPDR2.wav...\n",
      "Getting transcription for S17RPDR2.wav...\n",
      "Getting transcription for S18RPDR2.WAV...\n",
      "Getting transcription for S19RPDR2.wav...\n",
      "Getting transcription for S20RPDR2.WAV...\n",
      "Getting transcription for S21RPDR2.wav...\n",
      "Getting transcription for S22RPDR2.wav...\n",
      "Getting transcription for S24RPDR2.WAV...\n",
      "Getting transcription for S28RPDR2.wav...\n",
      "WER for HI speakers with high speech intelligibility: 0.06056056056056056\n",
      "WER for HI speakers medium speech intelligibility: 0.35872235872235875\n",
      "WER for HI speakers low speech intelligibility: 1.2654192654192655\n"
     ]
    }
   ],
   "source": [
    "## calculate WER for each speech intelligibility level\n",
    "HI_intell_high = [1,4,5,8,9,10]\n",
    "HI_intell_med = [6,7,12,15,23,25,26,27,29,30,31]\n",
    "HI_intell_low = [2,3,13,14,16,17,18,19,20,21,22,24,28]\n",
    "# import numpy as np\n",
    "# print(np.sort([*HI_intell_high, *HI_intell_med, *HI_intell_low]))\n",
    "\n",
    "def wer_from_txt_HI(i_li):\n",
    "    all_references = []\n",
    "    all_hypotheses = []\n",
    "    audio_dir = \"CorpusOfDeafSpeech\"\n",
    "    passage_name = \"RP\"\n",
    "    # Iterate over audio files\n",
    "    for i in i_li:          # os.listdir(audio_dir)\n",
    "        HI_subject = \"Subject \"+str(i)\n",
    "        dir_path = os.path.join(audio_dir, HI_subject, \"Passages\")\n",
    "        if i != 11:     # subject 11 doesn't have any passage recordings\n",
    "            for filename in os.listdir(dir_path):\n",
    "                if (filename.endswith(\".wav\") or filename.endswith(\".WAV\")) and filename.startswith(\"S\"+str(i)+passage_name):\n",
    "                    print(f\"Getting transcription for {filename}...\")\n",
    "                    \n",
    "                    filename_stripped = os.path.splitext(filename)[0]  # Get filename without extension\n",
    "                    txt_path = os.path.join(dir_path,filename_stripped+\"_medium.en.txt\")\n",
    "\n",
    "                    # Read from transcription file\n",
    "                    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        transcription = f.read()\n",
    "                    \n",
    "                    # Append reference and hypothesis for WER calculation\n",
    "                    all_references.append(reference_text)\n",
    "                    all_hypotheses.append(transcription)\n",
    "        \n",
    "    # Concatenate all references and hypotheses\n",
    "    concatenated_reference = \" \".join(all_references)\n",
    "    concatenated_hypothesis = \" \".join(all_hypotheses)\n",
    "\n",
    "    # Calculate overall WER\n",
    "    overall_wer_HI = wer(concatenated_reference, concatenated_hypothesis)\n",
    "    return overall_wer_HI\n",
    "\n",
    "WER_high = wer_from_txt_HI(HI_intell_high)\n",
    "WER_med = wer_from_txt_HI(HI_intell_med)\n",
    "WER_low = wer_from_txt_HI(HI_intell_low)\n",
    "print(f\"WER for HI speakers with high speech intelligibility: {WER_high}\")\n",
    "print(f\"WER for HI speakers medium speech intelligibility: {WER_med}\")\n",
    "print(f\"WER for HI speakers low speech intelligibility: {WER_low}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NH v.s. HI comparison\n",
    "\n",
    "| model size | WER_NH | WER_HI |\n",
    "| ---------- | ------ | ------ |\n",
    "| medium.en  |  5.23% | 69.28% |\n",
    "\n",
    "\n",
    "HI WER across speech intelligibility\n",
    "\n",
    "| Intelligibility | high | medium | low | overall |\n",
    "| --------------- | ---- | ------ | ----| ------- |\n",
    "|       WER       |   6.06%     |      35.87%     |     126.54%    |     69.28%    |\n",
    "|       WERR      |  15.90%     |     586.52%     |    2321.75%    |   1225.86%    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WER Relative (WERR): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER_NH: 5.23%\n",
      "WER_HI: 69.28%\n",
      "WERR: 1225.86%\n",
      "WERR (high): 15.90%\n",
      "WERR (medium): 586.52%\n",
      "WERR (low): 2321.75%\n"
     ]
    }
   ],
   "source": [
    "# overall_wer_HI = 0.6927927927927928\n",
    "# overall_wer_NH = 0.05225225225225225\n",
    "print(f\"WER_NH: {overall_wer_NH*100:.2f}%\")\n",
    "print(f\"WER_HI: {overall_wer_HI*100:.2f}%\")\n",
    "\n",
    "# calculate WERR\n",
    "werr = (overall_wer_HI - overall_wer_NH) / overall_wer_NH\n",
    "print(f\"WERR: {werr*100:.2f}%\")\n",
    "\n",
    "werr_high = (WER_high - overall_wer_NH) / overall_wer_NH\n",
    "print(f\"WERR (high): {werr_high*100:.2f}%\")\n",
    "werr_med = (WER_med - overall_wer_NH) / overall_wer_NH\n",
    "print(f\"WERR (medium): {werr_med*100:.2f}%\")\n",
    "werr_low = (WER_low - overall_wer_NH) / overall_wer_NH\n",
    "print(f\"WERR (low): {werr_low*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
